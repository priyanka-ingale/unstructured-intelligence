{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanka-ingale/unstructured-intelligence/blob/main/ReviewTextAnalysisFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ3Wz2aHf2LV"
      },
      "source": [
        "# Review Text Analysis - Topic Modeling with LDA\n",
        "This notebook performs topic modeling on restaurant and film reviews using Latent Dirichlet Allocation (LDA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbbVa4-xf2LW"
      },
      "source": [
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVIVEwkf2LW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B6EytFaf2LX",
        "outputId": "2738329e-8d34-4685-f271-4efb3121bb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK resources downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "print(\"NLTK resources downloaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t1K5S9yWf2LX",
        "outputId": "bafde70c-31ff-4dd5-f854-153855fd6fb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                             review       label\n",
              "0   1  About the shop: There is a restaurant in Soi L...  restaurant\n",
              "1   2  About the shop: Through this store for about t...  restaurant\n",
              "2   3  Roast Coffee &amp; Eatery is a restaurant loca...  restaurant\n",
              "3   4  Eat from the children. The shop is opposite. P...  restaurant\n",
              "4   5  The Ak 1 shop at another branch tastes the sam...  restaurant"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1194cb36-4f59-453b-92f5-82eb30eb420d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>About the shop: There is a restaurant in Soi L...</td>\n",
              "      <td>restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>About the shop: Through this store for about t...</td>\n",
              "      <td>restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Roast Coffee &amp;amp; Eatery is a restaurant loca...</td>\n",
              "      <td>restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Eat from the children. The shop is opposite. P...</td>\n",
              "      <td>restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The Ak 1 shop at another branch tastes the sam...</td>\n",
              "      <td>restaurant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1194cb36-4f59-453b-92f5-82eb30eb420d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1194cb36-4f59-453b-92f5-82eb30eb420d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1194cb36-4f59-453b-92f5-82eb30eb420d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reviews",
              "summary": "{\n  \"name\": \"reviews\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"On the table today, come to sweets again, usually eat a main course Japanese style fusion dishes delicious, not boring like a typical Japanese menu. Today, I come to a review of some of today&#39;s waffles, fruits, ice cream, vanilla balls to eat together. The taste is not as impressive as the main dish. I think that if you eat here and then eat more snacks to eat other stores better. The prices are good, but the food is not good.\",\n          \"For example, how to get rid of subtitles (CaO) by unscrupulous cinemas, for example, how to be (unknown which forces) to knock out the eggs (CaO2) below the spoiler... cautious (but no one should see ~ hahaha...) I think probably It should start from Raytheon 1 (say also \\u00e6\\u0192\\u00ad\\u00e6\\u201e\\u00a7~ I also recognized yesterday before the release of Raytheon 2! Really! After watching Raytheon 1, I\\u00e2\\u20ac\\u2122m going through it because of the base&gt;w&lt;)Only one of you can sit on The tronebut you two are born to be king Everyone thinks this younger brother is too conspiring, too tricky, and even the attitude of the four fighters is a bias towards Loki. They have not been warned in advance, but not necessarily what he did. They have also pointed their finger at him... Asgard, Divine, is a bright place. Similarly, a representative of the light represents darkness, then you say &quot;righteousness&quot;, as Asgardian will choose whoever they say, Loki wants to be King of Asgard, protector of night realm, but I saw him, just want to get the approval of the child... help my brother to ask for love! name! its! wonderful! A child who was jealous of my father! ! ! ! ! (Okay~ Odin Daddy~~~ Don\\u00e2\\u20ac\\u2122t hate you! \\u00e8\\u2030\\u00b3 !!! Create peace for the two countries... This child raises the \\u00e5\\u00aa\\u00b3+ and Fan\\u00e2\\u20ac\\u2122s official squad ah! Finally, the foundation attracts Laufy, even kills After dying his own biological father, he almost destroyed Jottenheim. In order to prove himself, he only exchanged a &quot;No, Loki...&quot;. One second, I saw his self-deprecating so-called relief. The so-called abandonment was accompanied by a decisive... ... He let go of his hand... (Then the brain fills the fairy princess and falls into the bad guy&#39;s hand to destroy the stalk. What is it! The sledgehammer can&#39;t say unscrupulous to his dad, but it is really fearless~! I don\\u00e2\\u20ac\\u2122t have to be like someone else, I can do it so well without thinking. (Oops~~ How to get more and more like Kaki became Snow White!!! No!!!! For an event! I missed a little TUT Almost the dark elves say Dongdong TUUUT, so please let me get the foundation of the base!!!!! The hidden soul of his hundred holes is hidden under the kimono, and the more he talks, the more he just represents him. The more eager to be seen, the attention, the concern... ...just what everyone sees is good, bad is bad.He is a evil spirit, he is a tricker of no evil, of course, Seeing is believing, so he should be such a person... If you want to... (Hammer brother is silently staring at the distance and being said to think of someone, I only think about the dungeon. Is the little goblin my fault?!!!) Loki talks with Frigga in the dungeon. I thought that Frigga would always go to the base for a small rebellion against Odin and would visit this little son in Kiki. Those who are sad, then self-injury, see the sorrow on her face, I almost have to go to the base to say ~ don&#39;t - don&#39;t hurt yourself! Don&#39;t use this method to hurt people who still care about you... So... Kiki extended his hand and wanted to grab Frigga&#39;s hand, she... disappeared... No one came... No one has ever... Small insertion... The Jane\\u00e2\\u20ac\\u2122s meal is so handsome!!! The first shot crossed the menu to see the eyes like a child!! After seeing the whole picture, like the brother of AG+ Warrior!!!! The body made me shamelessly left a saliva. (This is not right!) I am the first beauty of the Kiki Palace! Actually, I don\\u00e2\\u20ac\\u2122t want to open the lock and lick his toes at the foot of Kiki!! \\u00e5\\u0090\\u0090\\u00e8\\u2030\\u00b3!!!! Frigga is good! Fighting can be heroic! But I don\\u00e2\\u20ac\\u2122t have Think!!!! Unexpected!!!! Ma Ma!!!!!! The original base illusion comes from Ma Ma!!!!!!! That woman!!!!! Do you hide!!!!!!!! Mahjong!!!!!! Fu Lijia Ma Ma is killed for you! Wow!!!!!!!! Odin is more! Difficult! Yes! I can&#39;t escape the love of a mojo! I just got a sweet cake with Ma Ma. I just _(:\\u00d0\\u00b7&quot;\\u00e2\\u02c6\\u00a0)_No Think of it!!! Then the sledgehammer went to find a base to take risks~ (Then various crossovers started~~~ When the aliens appeared in the volley and half-hanging, it was simply Prometheus!!! What did I see after I took off my mask?! Soup old wet!!! (Sorry~! The teacher is more beautiful&gt;&lt;But maybe I miss him too!!!! Gatekeeper ran up the bridge to separate the UFO (let&#39;s call the alien) The alien spaceship is called this way~~~ Immediately say ~Captain~ Quickly open your large robot to flatten the aliens, or say ~\\u00e8\\u00af\\u00b6\\u00e8\\u00af\\u00b6~! The Pacific Rift opened to Asgard! Kiki all kinds of transformation!! Please pay attention! He changedGo through a low-key character that doesn&#39;t make people notice (repeated before and after, if I don&#39;t have a face blind!) Various avatars! Also hammer shield! ! ! ! (Is there a child&#39;s tamper shield?!!! Actually, the hammer iron is also very (???) Kiki&#39;s broken mouth, and all kinds of constant sayings are desperate to say, I don&#39;t know what to say (well~ I don&#39;t say I am looking forward to the kiss and let his Silver tongue fail.) It\\u00e2\\u20ac\\u2122s so cute! It\\u00e2\\u20ac\\u2122s too abnormal! It\\u00e2\\u20ac\\u2122s too abnormal with the Lei 1 women\\u00e2\\u20ac\\u2122s association (bar)! TUT must have been shut down for a long time, so I will say that sentence~you I finally came to see me~~(If you enter the Qiongyao sister\\u00e2\\u20ac\\u2122s play code at this moment, it must be my fault. Everything is wrong with me! After the UFO, I started to hammer the button!~~~ The back is still not converging broken mouth ~ too miss my brother TUTJane directly fainted past (she killed your mother, sledgehammer!!!!!!!! I hid behind the curtain to peek!) that person Where is the strength of the!!!!!! And the woman ~ not to die will not die! Let you curious and curious to release the material of the black Spidy! (Continue to go on the cross road ... far and then continue UFO Terrier !\\u00e9\\u00ba\\u00bb\\u00e8\\u203a\\u2039! This is how the rot is to kill the little three and the sweetheart to spend the beautiful honeymoon trip! Finally know What is the order of the officer to die with the death!!!!!! The common manipulator armor is satisfied here!!!!!!!!!!! The sledgehammer will still not look back to see him turn around in your head. The look after that! I have! Kiki! I see you, just like I can see Nini and Tintin! Only three of you!! Only one person suddenly sprouted the A factor particle and the black Spidey dark factor. (No attack and attack)! There are dark elves first slashed the knife after the smear of small stones at that time, the brain is filled with thousands of people also feel that this new cp is very saliva!! My base is based on the base!!!! !!!!!And Wang Da hammer, are you so rude to drop your brother&#39;s body with the woman ran and ran away?!!! (Kiki &quot;dead&quot; after watching his face paler, I am more perverted and hope to change back to the Frost Giant form!! For example, the hole in the sky of the primary school textbook~ The little monster without gravity is not the first time that the hammer brother went to Jottenheim to wear a throat and die?! When Ding sent people to the dark world to see, I saw the change before the resurrected spy appeared. At that time, I was more convinced that Kiki was not dead or dead! Finally, what Odin said! How heartfelt! It is the final approval, but actually!Odin pulled into the foundation! ! ! Does that mean that Odin is dead? ! ! ! It is impossible for Odin to authorize Kiki as the king of Asgard! impossible! ! ! Finally understand that the official version / fan version _ (: \\u00d0\\u00b7 &quot;\\u00e2\\u02c6\\u00a0) _ A hammer. . . . . . . . Are you going to come to the earth to eat chicken legs? ! ! !\",\n          \"Is a Chinese food shop round the small street of Soi Chokchai 4 Chinese New Year. I do not know who you are. I need to buy duck for an hour, the food is a must have. I do not like to eat here. Nothing but white flour The food is delicious and not eaten. The image tells the taste is good, delicious.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"movie\",\n          \"restaurant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Load the data\n",
        "reviews = pd.read_excel('IA2_1.xlsx')\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ya5UW9sf2LX"
      },
      "source": [
        "## 2. Text Preprocessing\n",
        "Transform reviews into a document-term matrix with:\n",
        "- Lemmatization\n",
        "- Stop-words and punctuation removal\n",
        "- Minimum document frequency = 5\n",
        "- Include 2-grams (bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGz2YDC8f2LY"
      },
      "outputs": [],
      "source": [
        "# 2. Initialize the Lemmatizer and Stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed_reviews = []\n",
        "\n",
        "# 3. Preprocess the reviews: Tokenize, Lemmatize, remove stop-words and punctuations.\n",
        "for doc in reviews['review']:\n",
        "    # Tokenize and Lowercase\n",
        "    tokens = nltk.word_tokenize(str(doc).lower())\n",
        "\n",
        "    # Lemmatize all words and remove punctuations (using .isalpha())\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]\n",
        "\n",
        "    # Remove stop-words\n",
        "    cleaned_tokens = [token for token in lemmatized_tokens if token not in stop_words]\n",
        "\n",
        "    # Join the tokens back into a single string for the Vectorizer\n",
        "    processed_reviews.append(\" \".join(cleaned_tokens))\n",
        "\n",
        "# 4. Create the Document-Term Matrix (DTM)\n",
        "vectorizer = CountVectorizer(min_df=5, ngram_range=(1, 2))\n",
        "dtm = vectorizer.fit_transform(processed_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzwNq-u7f2LY"
      },
      "source": [
        "## 3. LDA Topic Modeling\n",
        "Extract 6 topics from the reviews using Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "kzE4hNgjsMzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize the LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=6, random_state=12)\n",
        "\n",
        "# 2. Fit the model to the Document-Term Matrix (dtm) from Step 1\n",
        "lda_model.fit(dtm)\n",
        "\n",
        "# 3. Extract the topics of each document\n",
        "doc_topic_distribution = lda_model.transform(dtm)\n",
        "\n",
        "# Display the results for the first few documents\n",
        "print(\"Topic distribution matrix shape:\", doc_topic_distribution.shape)\n",
        "print(\"\\nTopic distribution for the first review (ID 1):\")\n",
        "print(doc_topic_distribution[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JRsnVONtAhI",
        "outputId": "bcc74870-0f9e-4e48-be46-9af2f42e653b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic distribution matrix shape: (1000, 6)\n",
            "\n",
            "Topic distribution for the first review (ID 1):\n",
            "[0.00100606 0.00100636 0.00100669 0.00100664 0.00100727 0.99496698]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rmDjPSf2LZ"
      },
      "source": [
        "## 4. Question 3: Topic Distribution for First 10 Restaurant and Movie Reviews\n",
        "\n",
        "Report the topic distribution and top-2 topics for:\n",
        "- First 10 restaurant reviews (ID = 1 to 10)\n",
        "- First 10 movie reviews (ID = 501 to 510)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define the ranges for restaurant and movie reviews based on IDs\n",
        "restaurant_ids = list(range(1, 11))\n",
        "movie_ids = list(range(501, 511))\n",
        "\n",
        "def topic_details(target_ids, distribution_matrix, dataframe):\n",
        "    print(f\"{'ID':<5} | {'Label':<12} | {'Top 2 Topics':<15} | {'Topic Distribution'}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for tid in target_ids:\n",
        "        # Match the ID from the CSV to the correct row index in the distribution matrix\n",
        "        row_indices = dataframe.index[dataframe['id'] == tid].tolist()\n",
        "\n",
        "        if row_indices:\n",
        "            idx = row_indices[0]\n",
        "            dist = distribution_matrix[idx]\n",
        "\n",
        "            # Find the indices of the top 2 topics (highest probabilities)\n",
        "            # argsort() sorts ascending, so we take the last two and reverse them\n",
        "            top_2_topics = dist.argsort()[-2:][::-1]\n",
        "\n",
        "            # Formatting the distribution for readability\n",
        "            dist_str = \", \".join([f\"{prob:.4f}\" for prob in dist])\n",
        "            label = dataframe.iloc[idx]['label']\n",
        "\n",
        "            print(f\"{tid:<5} | {label:<12} | {str(top_2_topics):<15} | [{dist_str}]\")\n",
        "\n",
        "# 2. Run the report for Restaurant reviews\n",
        "print(\"Topic Analysis: First 10 Restaurant Reviews (ID 1-10)\")\n",
        "topic_details(restaurant_ids, doc_topic_distribution, reviews)\n",
        "\n",
        "# 3. Run the report for Movie reviews\n",
        "print(\"\\nTopic Analysis: First 10 Movie Reviews (ID 501-510)\")\n",
        "topic_details(movie_ids, doc_topic_distribution, reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LkRVw4_E46t",
        "outputId": "ead92d73-cd0f-45a4-e85f-9f141e0d3ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic Analysis: First 10 Restaurant Reviews (ID 1-10)\n",
            "ID    | Label        | Top 2 Topics    | Topic Distribution\n",
            "--------------------------------------------------------------------------------\n",
            "1     | restaurant   | [5 4]           | [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.9950]\n",
            "2     | restaurant   | [5 1]           | [0.0011, 0.0559, 0.0011, 0.0011, 0.0011, 0.9397]\n",
            "3     | restaurant   | [5 4]           | [0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.9958]\n",
            "4     | restaurant   | [5 3]           | [0.0021, 0.0021, 0.0021, 0.2008, 0.0021, 0.7908]\n",
            "5     | restaurant   | [5 0]           | [0.0050, 0.0049, 0.0049, 0.0049, 0.0049, 0.9752]\n",
            "6     | restaurant   | [5 1]           | [0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.9957]\n",
            "7     | restaurant   | [5 4]           | [0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.9906]\n",
            "8     | restaurant   | [5 3]           | [0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.9916]\n",
            "9     | restaurant   | [5 2]           | [0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.9166]\n",
            "10    | restaurant   | [4 5]           | [0.0112, 0.0112, 0.0113, 0.0112, 0.5483, 0.4069]\n",
            "\n",
            "Topic Analysis: First 10 Movie Reviews (ID 501-510)\n",
            "ID    | Label        | Top 2 Topics    | Topic Distribution\n",
            "--------------------------------------------------------------------------------\n",
            "501   | movie        | [2 1]           | [0.0013, 0.2450, 0.5462, 0.0013, 0.2050, 0.0013]\n",
            "502   | movie        | [3 2]           | [0.0005, 0.1552, 0.3515, 0.4244, 0.0005, 0.0678]\n",
            "503   | movie        | [2 3]           | [0.0003, 0.0003, 0.5358, 0.4630, 0.0003, 0.0003]\n",
            "504   | movie        | [2 3]           | [0.0045, 0.0046, 0.5060, 0.4758, 0.0046, 0.0045]\n",
            "505   | movie        | [3 2]           | [0.0003, 0.0004, 0.1645, 0.8341, 0.0004, 0.0003]\n",
            "506   | movie        | [2 3]           | [0.0014, 0.2037, 0.4834, 0.2181, 0.0919, 0.0014]\n",
            "507   | movie        | [3 4]           | [0.0012, 0.0012, 0.0012, 0.6076, 0.3877, 0.0012]\n",
            "508   | movie        | [1 3]           | [0.0058, 0.9710, 0.0058, 0.0058, 0.0058, 0.0058]\n",
            "509   | movie        | [3 1]           | [0.0005, 0.0005, 0.0005, 0.9977, 0.0005, 0.0005]\n",
            "510   | movie        | [3 4]           | [0.0004, 0.0005, 0.0005, 0.6815, 0.3089, 0.0082]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i_lnYIz7H44y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DRfrc_mf2LZ"
      },
      "source": [
        "## 5. Question 4: Top-5 Terms for Each Topic\n",
        "\n",
        "Find and display the top-5 terms with highest weights for each of the 6 topics, then describe what each topic is about."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the feature names (terms) from the vectorizer used in Step 1\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 2. Loop through each of the 6 topics and extract the top 5 terms\n",
        "for topic_idx, topic in enumerate(lda_model.components_):\n",
        "    print(f\"Topic {topic_idx}:\")\n",
        "\n",
        "    # Sort weights in descending order and get the top 5 indices\n",
        "    # argsort() sorts ascending, so we take the last 5 elements [:-6:-1]\n",
        "    top_terms_indices = topic.argsort()[:-6:-1]\n",
        "\n",
        "    # Map indices back to the actual terms\n",
        "    top_5_terms = [terms[i] for i in top_terms_indices]\n",
        "\n",
        "    print(\" \".join(top_5_terms))\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Bz7AMCIs4Y",
        "outputId": "1b8a754f-daed-4877-eb33-f5288e6b6f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "war film wa soldier stalingrad\n",
            "--------------------\n",
            "Topic 1:\n",
            "quot people book ha also\n",
            "--------------------\n",
            "Topic 2:\n",
            "quot life love people wa\n",
            "--------------------\n",
            "Topic 3:\n",
            "quot film wa ha also\n",
            "--------------------\n",
            "Topic 4:\n",
            "wa people time woman also\n",
            "--------------------\n",
            "Topic 5:\n",
            "eat good delicious like food\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Report\n",
        "\n",
        "**Question 3:**\n",
        "\n",
        "\n",
        "\n",
        "*   **Restaurant Reviews (ID 1-10)**:\n",
        "\n",
        "    **Topic Distribution:** Almost all reviews in this group (IDs 1-9) are heavily dominated by Topic 5 (weights ~ 0.995).\n",
        "\n",
        "    **Top-2 Topics:** Typically [5, 4] or [5, 1]. Review 10 is an outlier, showing a mix of Topic 4 and Topic 5.\n",
        "\n",
        "    **Insight:** This high concentration in Topic 5 indicates a very consistent vocabulary (food, dining, taste) across the first 10 restaurant reviews.\n",
        "\n",
        "*   **Movie Reviews (ID 501-510)**:\n",
        "\n",
        "    **Topic Distribution:** These reviews show a much broader distribution across Topic 2 (Romance/Emotional) and Topic 3 (General Film).\n",
        "\n",
        "    **Top-2 Topics:** Common pairs include [2, 3], [3, 2], or [3, 4].\n",
        "\n",
        "    **Insight:** Movie reviews are more diverse in their themes, blending discussion of plot emotions (Topic 2) with general cinematic quality (Topic 3).\n",
        "\n",
        "  \n",
        "**Question 4: Top Terms and Topic Descriptions**\n",
        "\n",
        "Based on the top 5 terms with the highest weights, the 6 topics are described as follows:\n",
        "\n",
        "\n",
        "*   **Topic 0**\t(war, film, soldier, stalingrad)\n",
        "\tWar/Historical Films: Focuses on military history and conflict narratives.\n",
        "*   **Topic 1**\t(people, book, also, story)\n",
        "\tLiterature & People: Related to books, storytelling, and general human interest..\n",
        "*   **Topic 2**\t(life, love, people, emotional)\n",
        "\tRomance & Emotion: Centers on human relationships, \"love,\" and life lessons.\n",
        "*   **Topic 3**\t(film, movie, production, also)\n",
        "\tGeneral Film/Cinema: Broad discussion about the movie industry and production quality.\n",
        "*   **Topic 4**\t(people, time, woman, also)\n",
        "\tSociety & Time: General societal themes or time-based narratives.\n",
        "*   **Topic 5**\t(eat, good, delicious, food, like)\n",
        "\tRestaurant/Dining: The primary topic for food quality and restaurant experiences.\n",
        "\n",
        "\n",
        "**Question 5: Review Insights (ID 1 and ID 501)**\n",
        "\n",
        "\n",
        "\n",
        "*   **Review 1 [ID=1]:**\n",
        "\n",
        "    **Insights:** This review is almost exclusively about Topic 5 (weight 0.9950). The content details a visit to a restaurant in Soi Langsuan, describing specific French dishes like \"Duck l'orange\" and \"French onion soup.\" The model correctly identified this as a pure dining review based on keywords like \"eat,\" \"food,\" and \"delicious.\"\n",
        "\n",
        "    **Summary:** It is a standard culinary critique focusing on menu items and restaurant atmosphere.\n",
        "\n",
        "*   **Review 501 [ID=501]:**\n",
        "\n",
        "    **Insights:** This review is primarily associated with Topic 2 (weight 0.5462) and Topic 1 (weight 0.2450). It uses highly emotional and reflective language (\"I love you,\" \"unforgettable boy,\" \"confidant\"). While it doesn't mention a specific movie title in the opening, its vocabulary aligns with the \"Romance & Emotion\" and \"Literature\" themes.\n",
        "\n",
        "    **Summary:** It is a sentimental movie review or character analysis focusing on the emotional resonance of human connections rather than technical film aspects."
      ],
      "metadata": {
        "id": "6uTibCs_VzlO"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}